#!/usr/bin/env python3
"""
JSON Output Management Utility

This script provides command-line utilities for managing JSON outputs
generated by the SE Letters production pipeline.

Features:
- List all documents with JSON outputs
- View JSON outputs for specific documents
- Cleanup old versions
- Export outputs to different formats
- Generate reports on output statistics

Usage:
    python scripts/manage_json_outputs.py list
    python scripts/manage_json_outputs.py view <document_id>
    python scripts/manage_json_outputs.py cleanup --days 30
    python scripts/manage_json_outputs.py export <document_id> --format json
    python scripts/manage_json_outputs.py stats

Version: 1.0.0
Author: SE Letters Development Team
"""

import sys
import json
import argparse
from pathlib import Path
from typing import Dict, Any, List, Optional
from datetime import datetime, timedelta

# Add src to path
sys.path.insert(0, str(Path(__file__).parent.parent / "src"))

from se_letters.utils.json_output_manager import JSONOutputManager, get_pipeline_outputs, cleanup_old_pipeline_outputs


def list_documents(manager: JSONOutputManager) -> None:
    """List all documents with JSON outputs"""
    print("📋 Documents with JSON outputs:")
    print("=" * 50)
    
    documents = manager.list_all_documents()
    
    if not documents:
        print("No documents found with JSON outputs.")
        return
    
    for doc_id in documents:
        metadata = manager.get_document_metadata(doc_id)
        versions = manager.list_document_versions(doc_id)
        
        print(f"\n📄 Document ID: {doc_id}")
        if metadata:
            print(f"   📝 Name: {metadata.document_name}")
            print(f"   📁 Source: {metadata.source_file_path}")
            print(f"   ⏱️ Last processed: {metadata.processing_timestamp}")
            print(f"   🎯 Confidence: {metadata.confidence_score:.2f}")
            print(f"   ✅ Success: {metadata.success}")
        print(f"   📊 Versions: {len(versions)}")
        
        if versions:
            print(f"   📅 Latest: {versions[0]}")
            if len(versions) > 1:
                print(f"   📅 Oldest: {versions[-1]}")


def view_document(manager: JSONOutputManager, document_id: str, version: str = "latest") -> None:
    """View JSON outputs for a specific document"""
    print(f"👁️ Viewing document: {document_id} (version: {version})")
    print("=" * 50)
    
    # Get metadata
    metadata = manager.get_document_metadata(document_id)
    if metadata:
        print(f"📝 Document Name: {metadata.document_name}")
        print(f"📁 Source Path: {metadata.source_file_path}")
        print(f"⏱️ Processing Time: {metadata.processing_duration_ms:.2f}ms")
        print(f"🎯 Confidence Score: {metadata.confidence_score:.2f}")
        print(f"✅ Success: {metadata.success}")
        print(f"🔧 Pipeline Method: {metadata.pipeline_method}")
        print(f"📊 Outputs Saved: {', '.join(metadata.outputs_saved)}")
        print()
    
    # Get outputs
    outputs = manager.get_document_outputs(document_id, version)
    if not outputs:
        print(f"❌ No outputs found for document {document_id} (version: {version})")
        return
    
    for output_name, output_data in outputs.items():
        print(f"📄 {output_name.upper()}:")
        print("-" * 30)
        
        if output_name == "grok_metadata":
            # Display grok metadata in a structured way
            if "products" in output_data:
                print(f"   📦 Products found: {len(output_data['products'])}")
                for i, product in enumerate(output_data['products'][:3]):  # Show first 3
                    print(f"      {i+1}. {product.get('product_identifier', 'N/A')} - {product.get('range_label', 'N/A')}")
                if len(output_data['products']) > 3:
                    print(f"      ... and {len(output_data['products']) - 3} more")
            
            if "document_information" in output_data:
                doc_info = output_data["document_information"]
                print(f"   📄 Document Type: {doc_info.get('document_type', 'N/A')}")
                print(f"   📝 Document Title: {doc_info.get('document_title', 'N/A')}")
                print(f"   🌐 Language: {doc_info.get('language', 'N/A')}")
        
        elif output_name == "validation_result":
            print(f"   ✅ Compliant: {output_data.get('is_compliant', False)}")
            print(f"   🎯 Confidence: {output_data.get('confidence_score', 0.0):.2f}")
            print(f"   📦 Product Ranges: {output_data.get('product_ranges', [])}")
            if output_data.get('validation_errors'):
                print(f"   ❌ Errors: {len(output_data['validation_errors'])}")
        
        elif output_name == "processing_result":
            print(f"   ✅ Success: {output_data.get('success', False)}")
            print(f"   📊 Document ID: {output_data.get('document_id', 'N/A')}")
            print(f"   ⏱️ Processing Time: {output_data.get('processing_time_ms', 0):.2f}ms")
            print(f"   🎯 Confidence: {output_data.get('confidence_score', 0.0):.2f}")
            print(f"   📏 File Size: {output_data.get('file_size', 0):,} bytes")
        
        elif output_name == "pipeline_summary":
            print(f"   🔧 Pipeline Version: {output_data.get('pipeline_version', 'N/A')}")
            print(f"   🤖 XAI Model: {output_data.get('xai_model', 'N/A')}")
            print(f"   📄 Document Processor: {output_data.get('document_processor', 'N/A')}")
            print(f"   📦 Products Extracted: {output_data.get('products_extracted', 0)}")
            print(f"   🔧 Technical Specs Found: {output_data.get('technical_specs_found', False)}")
        
        print()


def cleanup_outputs(manager: JSONOutputManager, days: int = 30) -> None:
    """Clean up old JSON outputs"""
    print(f"🧹 Cleaning up outputs older than {days} days...")
    print("=" * 50)
    
    cleaned_count = manager.cleanup_old_outputs(days)
    
    if cleaned_count > 0:
        print(f"✅ Cleaned up {cleaned_count} old output versions")
    else:
        print("ℹ️ No old outputs to clean up")


def export_document(manager: JSONOutputManager, document_id: str, format_type: str = "json", output_file: str = None) -> None:
    """Export document outputs to different formats"""
    print(f"📤 Exporting document: {document_id} (format: {format_type})")
    print("=" * 50)
    
    outputs = manager.get_document_outputs(document_id)
    if not outputs:
        print(f"❌ No outputs found for document {document_id}")
        return
    
    if output_file is None:
        output_file = f"{document_id}_export.{format_type}"
    
    output_path = Path(output_file)
    
    if format_type.lower() == "json":
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(outputs, f, indent=2, ensure_ascii=False, default=str)
        print(f"✅ Exported to: {output_path}")
    
    elif format_type.lower() == "txt":
        with open(output_path, 'w', encoding='utf-8') as f:
            f.write(f"Document Export: {document_id}\n")
            f.write("=" * 50 + "\n\n")
            
            for output_name, output_data in outputs.items():
                f.write(f"{output_name.upper()}:\n")
                f.write("-" * 30 + "\n")
                f.write(json.dumps(output_data, indent=2, default=str))
                f.write("\n\n")
        print(f"✅ Exported to: {output_path}")
    
    else:
        print(f"❌ Unsupported format: {format_type}")


def show_statistics(manager: JSONOutputManager) -> None:
    """Show statistics about JSON outputs"""
    print("📊 JSON Output Statistics:")
    print("=" * 50)
    
    documents = manager.list_all_documents()
    total_documents = len(documents)
    
    if total_documents == 0:
        print("No documents found with JSON outputs.")
        return
    
    print(f"📄 Total Documents: {total_documents}")
    
    # Count successful vs failed
    successful_count = 0
    failed_count = 0
    total_versions = 0
    confidence_scores = []
    processing_times = []
    
    for doc_id in documents:
        metadata = manager.get_document_metadata(doc_id)
        versions = manager.list_document_versions(doc_id)
        total_versions += len(versions)
        
        if metadata:
            if metadata.success:
                successful_count += 1
                confidence_scores.append(metadata.confidence_score)
                processing_times.append(metadata.processing_duration_ms)
            else:
                failed_count += 1
    
    print(f"✅ Successful: {successful_count}")
    print(f"❌ Failed: {failed_count}")
    print(f"📊 Total Versions: {total_versions}")
    print(f"📊 Avg Versions per Document: {total_versions / total_documents:.1f}")
    
    if confidence_scores:
        print(f"🎯 Average Confidence: {sum(confidence_scores) / len(confidence_scores):.2f}")
        print(f"🎯 Min Confidence: {min(confidence_scores):.2f}")
        print(f"🎯 Max Confidence: {max(confidence_scores):.2f}")
    
    if processing_times:
        avg_time = sum(processing_times) / len(processing_times)
        print(f"⏱️ Average Processing Time: {avg_time:.2f}ms")
        print(f"⏱️ Min Processing Time: {min(processing_times):.2f}ms")
        print(f"⏱️ Max Processing Time: {max(processing_times):.2f}ms")


def main():
    """Main CLI interface"""
    parser = argparse.ArgumentParser(
        description="Manage JSON outputs from SE Letters production pipeline",
        formatter_class=argparse.RawDescriptionHelpFormatter
    )
    
    subparsers = parser.add_subparsers(dest='command', help='Available commands')
    
    # List command
    list_parser = subparsers.add_parser('list', help='List all documents with JSON outputs')
    
    # View command
    view_parser = subparsers.add_parser('view', help='View JSON outputs for a specific document')
    view_parser.add_argument('document_id', help='Document ID to view')
    view_parser.add_argument('--version', default='latest', help='Version to view (default: latest)')
    
    # Cleanup command
    cleanup_parser = subparsers.add_parser('cleanup', help='Clean up old JSON outputs')
    cleanup_parser.add_argument('--days', type=int, default=30, help='Number of days to retain (default: 30)')
    
    # Export command
    export_parser = subparsers.add_parser('export', help='Export document outputs to file')
    export_parser.add_argument('document_id', help='Document ID to export')
    export_parser.add_argument('--format', choices=['json', 'txt'], default='json', help='Export format (default: json)')
    export_parser.add_argument('--output', help='Output file path')
    
    # Stats command
    stats_parser = subparsers.add_parser('stats', help='Show statistics about JSON outputs')
    
    args = parser.parse_args()
    
    if not args.command:
        parser.print_help()
        return
    
    # Initialize manager
    manager = JSONOutputManager()
    
    # Execute command
    if args.command == 'list':
        list_documents(manager)
    
    elif args.command == 'view':
        view_document(manager, args.document_id, args.version)
    
    elif args.command == 'cleanup':
        cleanup_outputs(manager, args.days)
    
    elif args.command == 'export':
        export_document(manager, args.document_id, args.format, args.output)
    
    elif args.command == 'stats':
        show_statistics(manager)
    
    else:
        parser.print_help()


if __name__ == "__main__":
    main() 